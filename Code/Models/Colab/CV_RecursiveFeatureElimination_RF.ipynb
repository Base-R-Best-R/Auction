{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_RecursiveFeatureElimination_RF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on",
      "authorship_tag": "ABX9TyNBknhhWfFHh7jVPx/fIZnH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Base-R-Best-R/Auction/blob/main/Code/Models/Colab/CV_RecursiveFeatureElimination_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KW0kR-v0sGTR"
      },
      "outputs": [],
      "source": [
        "# call R in Python\n",
        "%reload_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UbyNwxeQsZPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# install and load packages\n",
        "install.packages(c(\"ranger\", \"Metrics\"))\n",
        "library(ranger)\n",
        "library(Metrics)"
      ],
      "metadata": {
        "id": "Sk5f64-jsaey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# load required data \n",
        "dat_aucs <- readRDS(\"drive/MyDrive/Colab Transfer/Aucs_df_feateng_split.RDS\")\n",
        "\n",
        "# exclude variables that are not supposed to be in the model\n",
        "lapply(dat_aucs, \\(x){\n",
        "\n",
        "  # remove\n",
        "  within(x, {\n",
        "    Contract_ID <- NULL\n",
        "    MLOT <- NULL\n",
        "    EW_Diff <- NULL\n",
        "    Winning_Bid <- Winning_Bid / 1e3\n",
        "    Eng_Est <- Eng_Est / 1e3\n",
        "  }) -> tmp\n",
        "  \n",
        "  # return\n",
        "  return(tmp)\n",
        "  \n",
        "}) -> dat_aucs_mod"
      ],
      "metadata": {
        "id": "cHLTwsM-sgSM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# CV function for recursive feature elimination\n",
        "rfe_rf_CV_par <- \\(data, nfolds = 5, splitrule_CV = \"variance\",\n",
        "                   min_node_size_CV = 1:4, max_depth_CV = seq(5, 70, 5),\n",
        "                   num_trees_CV = 1500, var_share = 0.75, \n",
        "                   nrounds = seq(2, 6),\n",
        "                   feat_share_CV = seq(0.3, 1, 0.2),\n",
        "                   eval_fun = Metrics::rmse,\n",
        "                   ncore = NULL,\n",
        "                   seed = 33){\n",
        "\n",
        "  # hot encode data\n",
        "  data <- model.matrix(~. + 0, data = data) |> as.data.frame()\n",
        "  \n",
        "  # ensure viable colnames\n",
        "  names(data) <- make.names(names(data))\n",
        "  \n",
        "  # reprod\n",
        "  set.seed(seed)\n",
        "\n",
        "  # generate CV folds\n",
        "  folds <- sample(nrow(data), nrow(data), replace = FALSE) |> \n",
        "            split(as.factor(1:nfolds)) |> setNames(1:nfolds) |> suppressWarnings()\n",
        "  \n",
        "  # set up parallel compute cluster\n",
        "  if(is.null(ncore)){\n",
        "    \n",
        "    # set amount of cores to the max available and leave one out\n",
        "    ncore <- parallel::detectCores() - 1\n",
        "    \n",
        "    # we parallelize over folds - the maximum number of occupied cores should thus be\n",
        "    ncore <- min(ncore, nfolds)\n",
        "    \n",
        "  } else {\n",
        "    \n",
        "    # find min of ncore and folds\n",
        "    ncore <- min(ncore, nfolds)\n",
        "    \n",
        "  }\n",
        "  \n",
        "  # set up cluster\n",
        "  clust <- parallel::makeCluster(ncore, outfile = \"\")\n",
        "\n",
        "  # tuning grid for forest\n",
        "  tgrid_RF <- expand.grid(\"feat_share\" = feat_share_CV,\n",
        "                          \"splitrule\" = splitrule_CV,\n",
        "                          \"min_node_size\" = min_node_size_CV,\n",
        "                          \"max_depth\" = max_depth_CV, \n",
        "                          \"num_trees\" = num_trees_CV,\n",
        "                          \"nrounds\" = nrounds)\n",
        "\n",
        "  # print cores that will be occupied\n",
        "  cat(paste0(Sys.time(), \" starting CV.\\n\", \n",
        "             (nrow(tgrid_RF) + sum(tgrid_RF[, \"nrounds\"])) * nfolds, \" forests to fit!\\n\",\n",
        "             length(clust),\" cores will be occupied by this process!\"))\n",
        "  \n",
        "   # loop over folds each is used as test set once\n",
        "   parallel::parLapply(clust, names(folds), \\(f_ind){\n",
        "\n",
        "    # test - bool \n",
        "    test_bool <- names(folds) %in% f_ind\n",
        "\n",
        "    # train and test\n",
        "    train_init <- data[do.call(c, folds[!test_bool]), ]\n",
        "    test_init <- data[folds[test_bool] |> unlist(), ]\n",
        "    \n",
        "    # train model using all features and CV input\n",
        "     apply(tgrid_RF, 1, \\(cv_inp){\n",
        "\n",
        "      # fit\n",
        "      ranger::ranger(Winning_Bid ~., mtry = floor(as.numeric(cv_inp[1]) * ncol(train_init)),\n",
        "                     splitrule = cv_inp[2],\n",
        "                     min.node.size = as.numeric(cv_inp[3]),\n",
        "                     max.depth = as.numeric(cv_inp[4]), \n",
        "                     num.trees = as.numeric(cv_inp[5]),\n",
        "                     data = train_init,\n",
        "                     importance = \"permutation\") -> fit_rf\n",
        "       \n",
        "       # importance\n",
        "       importance <- fit_rf[[\"variable.importance\"]]\n",
        "       \n",
        "       # sort and choose\n",
        "       names_sub <- sort(importance, \n",
        "                         decreasing = TRUE)[1:floor(length(importance) * var_share)] |> names()\n",
        "          \n",
        "       # data to be overwritten (we will remove features from this object)\n",
        "       # first we take var_share * columns of the most important variables\n",
        "       dat_it <- train_init[, c(\"Winning_Bid\", names_sub)] \n",
        "       \n",
        "       # recursive feature elimination\n",
        "       for(i in 1:as.numeric(cv_inp[6])){\n",
        "         \n",
        "         # fit rf\n",
        "         ranger::ranger(Winning_Bid ~., mtry = floor(as.numeric(cv_inp[1]) * ncol(dat_it)),\n",
        "                        splitrule = cv_inp[2],\n",
        "                        min.node.size = as.numeric(cv_inp[3]),\n",
        "                        max.depth = as.numeric(cv_inp[4]), \n",
        "                        num.trees = as.numeric(cv_inp[5]),\n",
        "                        data = dat_it,\n",
        "                        importance = \"permutation\") -> fit_rf_it\n",
        "         \n",
        "         # importance \n",
        "         importance_it <- fit_rf_it[[\"variable.importance\"]]\n",
        "      \n",
        "         # sort and choose\n",
        "         names_sub_it <- sort(importance_it, \n",
        "                              decreasing = TRUE)[1:floor(length(importance_it) * var_share)] |> names()\n",
        "         \n",
        "         # overwrite data \n",
        "         dat_it <- dat_it[, c(\"Winning_Bid\", names_sub_it)]\n",
        "\n",
        "         # in last recursive call write performance into storage\n",
        "         if(i == as.numeric(cv_inp[6])){\n",
        "\n",
        "           # final rf\n",
        "           ranger::ranger(Winning_Bid ~., mtry = floor(as.numeric(cv_inp[1]) * ncol(dat_it)),\n",
        "                          splitrule = cv_inp[2],\n",
        "                          min.node.size = as.numeric(cv_inp[3]),\n",
        "                          max.depth = as.numeric(cv_inp[4]), \n",
        "                          num.trees = as.numeric(cv_inp[5]),\n",
        "                          data = dat_it,\n",
        "                          importance = \"permutation\") -> fit_rf_it\n",
        "            \n",
        "           # generate test set with all chosen variables\n",
        "           dat_test <- test_init[, c(\"Winning_Bid\", names_sub_it)]\n",
        "           \n",
        "           # predict on test set\n",
        "           pred <- predict(fit_rf_it, dat_test)\n",
        " \n",
        "           # eval\n",
        "           eval_res <- eval_fun(actual = dat_test[, \"Winning_Bid\"],\n",
        "                                predicted = pred[[\"predictions\"]])\n",
        "           \n",
        "           # save and return performance \n",
        "           return(c(cv_inp[1], # feat_share\n",
        "                    cv_inp[2], # splitrule\n",
        "                    cv_inp[3], # min.node.size\n",
        "                    cv_inp[4], # max.depth\n",
        "                    cv_inp[5], # ntrees\n",
        "                    cv_inp[6], # nrounds \n",
        "                    \"var_share\" = var_share,\n",
        "                    \"performance\" = eval_res))\n",
        "        }\n",
        " \n",
        "       }\n",
        "    \n",
        "      }) |> as.data.frame() |> setNames(paste0(\"RF_\", 1:nrow(tgrid_RF)))\n",
        "    \n",
        "  }) |> setNames(1:nfolds) -> tmp\n",
        "  \n",
        "  # release cores \n",
        "  on.exit(parallel::stopCluster(clust), add = TRUE)\n",
        "  \n",
        "  # return\n",
        "  return(tmp)\n",
        "  \n",
        "}"
      ],
      "metadata": {
        "id": "ZWHEkBKatCL_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# exec\n",
        "rfe_rf_CV_par(data = dat_aucs_mod[[\"Train\"]], nfolds = 5, splitrule_CV = \"variance\",\n",
        "               min_node_size_CV = seq(1, 5, 2), max_depth_CV = seq(5, 35, 10),\n",
        "               num_trees_CV = c(1000, 1500), var_share = 0.6, \n",
        "               nrounds = seq(2, 10, 2),\n",
        "               feat_share = seq(0.7, 0.9, 0.1),\n",
        "               eval_fun = Metrics::rmse,\n",
        "               ncore = 2,\n",
        "               seed = 33) -> res\n",
        "\n",
        "# save\n",
        "saveRDS(res, \"drive/MyDrive/Master_Thesis/Models_MT/NestedCV_rfe_rf.RDS\")"
      ],
      "metadata": {
        "id": "khhdDVuKtKv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# unmount drive \n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "AduYIGd7tcha"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}