{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Base-R-Best-R/Auction/blob/main/Code/Models/Colab/Parallel_NestedCV_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IaY2MLD58urF"
      },
      "outputs": [],
      "source": [
        "# call R in Python\n",
        "%reload_ext rpy2.ipython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jvLNPABW9FQh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb7da566-d62d-47dd-f943-b9ceca9644fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount gdrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CGwFhs89hA7"
      },
      "outputs": [],
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# install and load packages\n",
        "install.packages(c(\"ranger\", \"logisticPCA\", \"Metrics\"))\n",
        "library(ranger)\n",
        "library(logisticPCA)\n",
        "library(Metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HBVH4Q06-dUi"
      },
      "outputs": [],
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# load required data \n",
        "dat_aucs <- readRDS(\"drive/MyDrive/Colab Transfer/Aucs_df_feateng_split.RDS\")\n",
        "\n",
        "# training \n",
        "dat_aucs_train <- dat_aucs[[\"Train\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6B_rHgzOB4TI"
      },
      "outputs": [],
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# write CV function\n",
        "log_PCA_rf_CV_par <- \\(data, nfolds = 5, m_nest_CV = seq(1, 13, 2), \n",
        "                   k_desc_CV = seq(2, 20, 2), k_ven_CV = seq(2, 20, 2), \n",
        "                   k_vendInt_CV = seq(2, 20, 2), splitrule_CV = \"variance\",\n",
        "                   min_node_size_CV = 1:4, max_depth_CV = seq(5, 70, 5), mtry_incr = 5,\n",
        "                   num_trees_CV = 1500, mtry_incr_start = 5, eval_fun = Metrics::rmse,\n",
        "                   ncore = NULL){\n",
        "      \n",
        "  # rm unwanted cols\n",
        "  within(data,{\n",
        "    Contract_ID <- NULL\n",
        "    MLOT <- NULL\n",
        "    EW_Diff <- NULL\n",
        "    Winning_Bid <- Winning_Bid / 1e3\n",
        "    Eng_Est <- Eng_Est / 1e3\n",
        "  }) -> data\n",
        "\n",
        "  \n",
        "  # bools\n",
        "  vend_cols_log <- names(data) |> stringr::str_detect(\"Vend_\") \n",
        "  interact_cols <- names(data) |> stringr::str_detect(\"_x_\")\n",
        "  descr_words <- which(!vend_cols_log)[-c(1:7)]\n",
        "  Vend_not_int <- vend_cols_log & (!interact_cols)\n",
        "  \n",
        "  # generate CV folds\n",
        "  folds <- sample(nrow(data), nrow(data), replace = FALSE) |> \n",
        "            split(as.factor(1:nfolds)) |> setNames(1:nfolds) |> suppressWarnings()\n",
        "\n",
        "  # tuning grid init\n",
        "  tgrid_PC <- expand.grid(\"nPCA_Desc\" = k_desc_CV,\n",
        "                          \"nPCA_Vend\" = k_ven_CV,\n",
        "                          \"nPCA_VendInt\" = k_vendInt_CV)\n",
        "  \n",
        "  # set up parallel compute cluster\n",
        "  if(is.null(ncore)){\n",
        "    \n",
        "    # set amount of cores to the max available and leave one out\n",
        "    ncore <- parallel::detectCores() - 1\n",
        "    \n",
        "    # we parallelize over folds - the maximum number of occupied cores should thus be\n",
        "    ncore <- min(ncore, nfolds)\n",
        "    \n",
        "  } else {\n",
        "    \n",
        "    # find min of ncore and folds\n",
        "    ncore <- min(ncore, nfolds)\n",
        "    \n",
        "  }\n",
        "\n",
        "  # set up cluster\n",
        "  clust <- parallel::makeCluster(ncore, outfile = \"\")\n",
        "\n",
        "  # print cores that will be occupied\n",
        "  cat(paste0(length(clust), \" cores will be occupied by this process!\"))\n",
        "  \n",
        "  # loop over folds each is used as test set once\n",
        "  parallel::parLapply(clust, names(folds), \\(f_ind){\n",
        "    \n",
        "      # test - bool \n",
        "      test_bool <- names(folds) %in% f_ind\n",
        "\n",
        "      # train and test\n",
        "      train <- data[do.call(c, folds[!test_bool]), ]\n",
        "      test <- data[folds[test_bool] |> unlist(), ]\n",
        "      \n",
        "      # separate into desc / Vend / Vend_int\n",
        "      grps <- list(\"Train\" = list(\"Description\" = train[, descr_words], \n",
        "                                  \"Vendor\" = train[, Vend_not_int],\n",
        "                                  \"Vendor_Interaction\" = train[, interact_cols]),\n",
        "                   \"Test\" = list(\"Description\" = test[, descr_words], \n",
        "                                  \"Vendor\" = test[, Vend_not_int],\n",
        "                                  \"Vendor_Interaction\" = test[, interact_cols]))\n",
        "      \n",
        "      # nested CV\n",
        "      apply(tgrid_PC, 1, \\(x){\n",
        "\n",
        "        # Over all 3 binary subsets\n",
        "        Map(\\(dat_train, dat_test, kk){\n",
        "\n",
        "          # CV for m of logistic PCA\n",
        "          cv_PCA <- logisticPCA::cv.lpca(dat_train, ms = m_nest_CV, ks = kk)\n",
        "        \n",
        "          # fit\n",
        "          fit_PCA <- logisticPCA::logisticPCA(dat_train, k = kk, \n",
        "                                 m = colnames(cv_PCA)[which.min(cv_PCA)] |> as.numeric())\n",
        "            \n",
        "          # predict \n",
        "          pred_PCA <- predict(fit_PCA, dat_test, type = \"PCs\") # name this (variable importance)\n",
        "          \n",
        "          # return\n",
        "          return(list(\"Fit_PCA\" = fit_PCA,\n",
        "                      \"Pred_PCA\" = pred_PCA))\n",
        "          \n",
        "        }, grps[[\"Train\"]], grps[[\"Test\"]], x) -> fitted_PCs\n",
        "\n",
        "        # assemble PCA dataset\n",
        "        PC_dfs <- Map(\\(tt, PCAtt, bool){\n",
        "    \n",
        "          # bool for supset\n",
        "          if(bool){\n",
        "            \n",
        "            # subset from fit\n",
        "            PCs <- lapply(fitted_PCs, \"[[\", PCAtt) |> lapply(\\(z) as.data.frame(z[[\"PCs\"]])) \n",
        "              \n",
        "          } else {\n",
        "            \n",
        "            PCs <- lapply(fitted_PCs, \\(t) as.data.frame(t[[PCAtt]]))\n",
        "            \n",
        "          }\n",
        "    \n",
        "          # assemble new test and train set\n",
        "          cbind(tt[1:7], do.call(cbind, PCs))\n",
        "          \n",
        "        }, list(train, test), \n",
        "        c(\"Fit_PCA\", \"Pred_PCA\"), c(TRUE, FALSE)) |> setNames(c(\"Train\", \"Test\"))\n",
        "\n",
        "        # mtry value depending on number of PCs and thus added now\n",
        "        mtry_CV <- seq(mtry_incr_start, ncol(PC_dfs[[\"Train\"]]), mtry_incr)\n",
        "        \n",
        "        # RF tuning grid \n",
        "        tgrid_RF <- expand.grid(\"mtry\" = mtry_CV,\n",
        "                                \"splitrule\" = splitrule_CV,\n",
        "                                \"min_node_size\" = min_node_size_CV,\n",
        "                                \"max_depth\" = max_depth_CV, \n",
        "                                \"num_trees\" = num_trees_CV)\n",
        "        \n",
        "        ## Random forest ##\n",
        "        apply(tgrid_RF, 1, \\(cv_inp){\n",
        "          \n",
        "          # fit\n",
        "          ranger::ranger(Winning_Bid ~., mtry = as.numeric(cv_inp[1]),\n",
        "                         splitrule = cv_inp[2],\n",
        "                         min.node.size = as.numeric(cv_inp[3]),\n",
        "                         max.depth = as.numeric(cv_inp[4]), \n",
        "                         num.trees = as.numeric(cv_inp[5]),\n",
        "                         data = PC_dfs[[\"Train\"]]) -> fit_rf\n",
        "          \n",
        "          # predict \n",
        "          pred <- predict(fit_rf, PC_dfs[[\"Test\"]])\n",
        "          \n",
        "          # calc RMSE\n",
        "          eval_res <- eval_fun(actual = PC_dfs[[\"Test\"]][, \"Winning_Bid\"], predicted = pred[[\"predictions\"]])\n",
        "          \n",
        "          # return result and inputs\n",
        "          return(c(cv_inp[1], # mtry\n",
        "                   cv_inp[2], # splitrule\n",
        "                   cv_inp[3], # min.node.size\n",
        "                   cv_inp[4], # max.depth\n",
        "                   cv_inp[5], # ntrees\n",
        "                   x[1], # nPCA Desc\n",
        "                   x[2], # nPCA Vend\n",
        "                   x[3], # nPCA VendInt\n",
        "                   \"performance\" = eval_res)) \n",
        "          \n",
        "      }) |> as.data.frame() |> setNames(paste0(\"RF_\", 1:nrow(tgrid_RF)))\n",
        "    }) |> setNames(paste0(\"PCA_\", 1:nrow(tgrid_PC)))\n",
        "  }) |> setNames(1:nfolds) -> tmp\n",
        "  \n",
        "  # release cores \n",
        "  on.exit(parallel::stopCluster(clust), add = TRUE)\n",
        "  \n",
        "  # return\n",
        "  return(tmp)\n",
        "  \n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2v_hGkvt_Aak"
      },
      "outputs": [],
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# Run CV \n",
        "log_PCA_rf_CV_par(dat_aucs_train, nfolds = 5, m_nest_CV = c(3, 8, 12), \n",
        "              k_desc_CV = c(20, 30), k_ven_CV = c(20, 30), \n",
        "              k_vendInt_CV = c(20, 30), splitrule_CV = \"variance\",\n",
        "              min_node_size_CV = c(1, 3, 5), max_depth_CV = c(30, 50, 70, 110), \n",
        "              mtry_incr = 5, ncore = 2) -> res\n",
        "\n",
        "# save \n",
        "# saveRDS(res, \"drive/MyDrive/Master_Thesis/Models_MT/NestedCV_logPCA_rf_v2.RDS\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# R\n",
        "%%R\n",
        "\n",
        "# 2nd run \n",
        "log_PCA_rf_CV_par(dat_aucs_train, nfolds = 5, m_nest_CV = c(5, 8, 12), \n",
        "              k_desc_CV = c(15, 20, 25), k_ven_CV = c(5, 10, 15), \n",
        "              k_vendInt_CV = c(15, 20, 25), splitrule_CV = \"variance\",\n",
        "              min_node_size_CV = c(1, 3), max_depth_CV = c(30, 50, 70), \n",
        "              mtry_incr = 5, ncore = 2) -> res\n",
        "\n",
        "# save\n",
        "saveRDS(res, \"drive/MyDrive/Master_Thesis/Models_MT/NestedCV_logPCA_rf_r3.RDS\")"
      ],
      "metadata": {
        "id": "sB44AI4OjLCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "650273ed-2d27-4911-ba12-4a8e227d9d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 cores will be occupied by this process!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkkvHLen-cU-"
      },
      "outputs": [],
      "source": [
        "# unmount drive \n",
        "drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Parallel_NestedCV_RF.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgCyurIB3EqZIJ9yVQFXXx",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}