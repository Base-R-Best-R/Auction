---
title: |
       | 09 Elastic Net GLM
author: "Fabian Blasch"
date: "`r format(Sys.Date(), format = '%m/%d/%Y')`"
header-includes:
   - \usepackage{amsmath}
   - \usepackage{amssymb}
   - \usepackage{float}
   - \usepackage{titling}
   - \usepackage{xcolor}
output: 
   pdf_document:
      number_sections: TRUE
---

# Load Data

```{r, results = "hide", message = FALSE, warning = FALSE}
# knitr options
knitr::opts_chunk$set(echo = TRUE,
                      fig.pos = "center",
                      fig.width = 8,
                      fig.height = 4,
                      fig.pos = "H")

# source AUX
source("./../Misc/Auxilliary.R")
source("./../Misc/model_eval.R")

# packages
get.package(c("lubridate", "glmnet", "glmnetUtils", "tidyverse", "patchwork"))

# load data
dat_bids <- readRDS("./../../Data/Bid Tab RDS/Bids_df_split.RDS")
dat_bids_ind <- readRDS("./../../Data/Bid Tab RDS/Bids_id_df_split.RDS")
dat_aucs <- readRDS("./../../Data/Bid Tab RDS/Aucs_df_split.RDS")
dat_aucs_tot <- readRDS("./../../Data/Bid Tab RDS/Aucs_df.RDS")
dat_aucs_eng <- readRDS("./../../Data/Bid Tab RDS/Aucs_df_feateng_split.RDS")
```

# Bid Level

## No Feature Engineering

### Variable Removal

```{r}
# exclude variables that are not supposed to be in the model
lapply(dat_bids_ind, \(x){

  # remove
  x$Vendor_Name <- NULL
  x$Contract_ID <- NULL
  
  # for now remove vendor ID to reduce training time
  x$Vendor_ID <- NULL
  
  # return
  return(x)
  
}) -> dat_bids_mod

# assign training set
dat_train <- dat_bids_mod[["Train"]]
```


### Cross Validation

```{r}
# cross validation

## RAN ONCE ## 
# cvfit <- glmnetUtils::cva.glmnet(Win ~., data = dat_train,
#                                  family = binomial(link = "logit"),
#                                  type.measure = "deviance", nfolds = 10,
#                                  alpha = seq(0, 1, 0.05), nlambda = 100)

# save
# saveRDS(cvfit, "./../../Data/Models/Glmnets/Raw/cvfitnI.RDS")

# read file 
cvfit <- readRDS("./../../Data/Models/Glmnets/Raw/cvfitnI.RDS")

# plot fit
plot(cvfit, c.legend = 0.5, main = "Cross Validation Results")
```

### Best Model

```{r}
# obtain best model
per_matrix <- do.call(rbind, Map(function(x, y){

 cbind("Per" = x$cvm,
       "Lambda" = x$lambda,
       "Alpha" = rep(y, length(x$lambda)))

}, cvfit$modlist, cvfit$alpha))

# best performing paremeters
best_para <- per_matrix[which.min(per_matrix[, "Per"]), ]

# fit model using best parameters
fit_fin <- glmnetUtils::glmnet(Win ~., data = dat_train, 
                               family = binomial(link = "logit"),
                               alpha = best_para["Alpha"], 
                               lambda = best_para["Lambda"])

# predict
pred_vals <- predict(fit_fin, dat_train, type = "response")

# pred
Eval_Curve_prel(list(pred_vals), 
                dat_train[["Win"]]) -> prelim

# curbe
par(mfrow = c(1, 2))
Eval_Curve(prelim, col = "forestgreen", leg_text = "Glmnet")
Eval_Curve(prelim, col = 4, leg_text = "Glmnet", RoC = FALSE, 
           act_label = dat_train[["Win"]])
```

### Variable Importance

```{r}
# coefficients
coefft <- coef(fit_fin, s = "lambda.min")
coef_ordered <- coefft[order(abs(coefft[, 1]), decreasing = TRUE), ]
signum <- coef_ordered[-1] |> sign()

# print est model parameters
knitr::kable(best_para, col.names = c("Final Model"))

# generate data for varImp plot
TopvarImp <- varImp(fit_fin, lambda = fit_fin$lambda)  %>%
   dplyr::filter(Overall != 0) %>% 
   arrange(desc(Overall)) %>% 
   slice_max(Overall, n = 10)

# Plot
plot_varimp <- ggplot2::ggplot(TopvarImp, aes(x = reorder(rownames(TopvarImp), Overall), y = Overall)) +
  geom_point(color = "blue", size = 4, alpha = 0.6) +
  geom_segment(aes(x = rownames(TopvarImp), xend = rownames(TopvarImp), y = 0, yend = Overall), 
               color = "skyblue") +
  xlab("Variable") +
  ylab("Overall Importance") +
  theme_light() +
  coord_flip() 

# plot
plot_varimp

# signs
knitr::kable(ifelse(signum < 0, "-", "+"), col.names = "Sign")
```

## Data Including Rival Bidders (No FeatEng)

### Variable Removal

```{r}
# exclude variables that are not supposed to be in the model
lapply(dat_bids_ind, \(x){

  # remove
  x$Vendor_Name <- NULL
  # x$Contract_ID <- NULL
  
  # for now remove vendor ID to reduce training time
  # x$Vendor_ID <- NULL
  
  # return
  return(x)
  
}) -> dat_bids_ind_mod

# training set
dat_train_ind <- dat_bids_ind_mod[["Train"]]
```


### Cross Validation

```{r}
# cross validation

## RAN ONCE ## 
# cvfit <- glmnetUtils::cva.glmnet(Win ~., data = dat_train_ind,
#                                  family = binomial(link = "logit"),
#                                  type.measure = "deviance", nfolds = 10,
#                                  alpha = seq(0, 1, 0.05), nlambda = 100)
# beepr::beep(sound = 4)

# save
# saveRDS(cvfit, "./../../Data/Models/Glmnets/Raw/cvfitid.RDS")

# read file 
cvfit <- readRDS("./../../Data/Models/Glmnets/Raw/cvfitid.RDS")

# plot fit
plot(cvfit, c.legend = 0.5, main = "Cross Validation Results")
```

### Best Model

```{r}
# obtain best model
per_matrix <- do.call(rbind, Map(function(x, y){

 cbind("Per" = x$cvm,
       "Lambda" = x$lambda,
       "Alpha" = rep(y, length(x$lambda)))

}, cvfit$modlist, cvfit$alpha))

# best performing paremeters
best_para <- per_matrix[which.min(per_matrix[, "Per"]), ]

# fit model using best parameters
fit_fin <- glmnetUtils::glmnet(Win ~., data = dat_train_ind, 
                               family = binomial(link = "logit"),
                               alpha = best_para["Alpha"], 
                               lambda = best_para["Lambda"])

# predict
pred_vals <- predict(fit_fin, dat_train_ind, type = "response")

# pred
Eval_Curve_prel(list(pred_vals), 
                dat_train_ind[["Win"]]) -> prelim

# curbe
par(mfrow = c(1, 2))
Eval_Curve(prelim, col = "forestgreen", leg_text = "Glmnet")
Eval_Curve(prelim, col = 4, leg_text = "Glmnet", RoC = FALSE, 
           act_label = dat_train_ind[["Win"]])
```

### Variable Importance

```{r}
# coefficients
coefft <- coef(fit_fin, s = "lambda.min")
coef_ordered <- coefft[order(abs(coefft[, 1]), decreasing = TRUE), ]
signum <- coef_ordered[-1] |> sign()

# print est model parameters
knitr::kable(best_para, col.names = c("Final Model"))

# generate data for varImp plot
TopvarImp <- varImp(fit_fin, lambda = fit_fin$lambda)  %>%
   dplyr::filter(Overall != 0) %>% 
   arrange(desc(Overall)) %>% 
   slice_max(Overall, n = 10)

# Plot
plot_varimp <- ggplot2::ggplot(TopvarImp, aes(x = reorder(rownames(TopvarImp), Overall), y = Overall)) +
  geom_point(color = "blue", size = 4, alpha = 0.6) +
  geom_segment(aes(x = rownames(TopvarImp), xend = rownames(TopvarImp), y = 0, yend = Overall), 
               color = "skyblue") +
  xlab("Variable") +
  ylab("Overall Importance") +
  theme_light() +
  coord_flip() 

# plot
plot_varimp

# signs
knitr::kable(ifelse(signum < 0, "-", "+"), col.names = "Sign")
```

# Auction Level

## Finding the correct link

```{r}
# check fit
print(Dens_hist_plot(train, "Winning_Bid", dist = "exponential", distFUN = dexp, bins = 100, bg_alt = TRUE) +
Dens_hist_plot(train, "Winning_Bid", dist = "normal", distFUN = dnorm, bins = 100) /
Dens_hist_plot(train, "Winning_Bid", dist = "gamma", distFUN = dgamma, lower_b = 0.005, bins = 100))
```

## No Feature Engineering

### Variable Removal

```{r}
# exclude variables that are not supposed to be in the model
lapply(dat_aucs, \(x){

  # remove
  x$Contract_ID <- NULL
  x$MLOT <- NULL
  x$Eng_Est <- NULL
  # x$EW_Diff <- NULL
  x$Winning_Bid_Log <- log(x$Winning_Bid)
  x$Winning_Bid <- NULL
  
  # return
  return(x)
  
}) -> dat_aucs_mod

# assign training set
dat_train_aucs <- dat_aucs_mod[["Train"]]
```

### Cross Validation

#### EW_Diff

```{r}
# cross validation

## RAN ONCE ## 
# cvfit_auc <- glmnetUtils::cva.glmnet(EW_Diff ~., data = dat_train_aucs,
#                                  family = gaussian(link = "identity"),
#                                  type.measure = "mse", nfolds = 5,
#                                  alpha = c(0.1, 1), nlambda = 15)

# save
# saveRDS(cvfit, "./../../Data/Models/Glmnets/Raw/cvfitnI.RDS")

# read file 
cvfit_auc <- readRDS("./../../Data/Models/Glmnets/Raw/cvfitnI.RDS")

# plot fit
plot(cvfit_auc, c.legend = 0.5, main = "Cross Validation Results")
```

#### Winning Bid

```{r}
# cross validation

## RAN ONCE ## 
# cvfit_auc2 <- glmnetUtils::cva.glmnet(Winning_Bid_Log ~., data = dat_train_aucs,
#                                      family = gaussian(link = "identity"),
#                                      type.measure = "mse", nfolds = 5,
#                                      alpha = c(0.01, seq(0, 1, 0.05), 0.99),
#                                      nlambda = 100)

# save
# saveRDS(cvfit_auc2, "./../../Data/Models/Glmnets/Raw/cvfitAucLWBid.RDS")

# read file 
cvfit_auc2 <- readRDS("./../../Data/Models/Glmnets/Raw/cvfitAucLWBid.RDS")

# plot fit
plot(cvfit_auc2, c.legend = 0.5, main = "Cross Validation Results")
```

### Best Model

#### EW_Diff

```{r}
# obtain best model
per_matrix_auc <- do.call(rbind, Map(function(x, y){

 cbind("Per" = x$cvm,
       "Lambda" = x$lambda,
       "Alpha" = rep(y, length(x$lambda)))

}, cvfit_auc$modlist, cvfit_auc$alpha))

# best performing paremeters
best_para_auc <- per_matrix_auc[which.min(per_matrix_auc[, "Per"]), ]

# fit model using best parameters
fit_fin_auc <- glmnetUtils::glmnet(EW_Diff ~., data = dat_train_aucs,
                               family = gaussian(link = "identity"),
                               alpha = best_para_auc["Alpha"], 
                               lambda = best_para_auc["Lambda"])

# predict
pred_vals_auc <- predict(fit_fin_auc, dat_train_aucs, alpha = 1)

# check preds
par(mfrow = c(1, 2))
boxplot(dat_train_aucs[["EW_Diff"]], ylim = c(-3e6, 3e6))
boxplot(pred_vals_auc, ylim = c(-3e6, 3e6))

# rmse
sqrt(sum((dat_train_aucs[["EW_Diff"]] - pred_vals_auc)^2) / length(pred_vals_auc))

```

#### Winning Bid

```{r}
# obtain best model
per_matrix_auc2 <- do.call(rbind, Map(function(x, y){

 cbind("Per" = x$cvm,
       "Lambda" = x$lambda,
       "Alpha" = rep(y, length(x$lambda)))

}, cvfit_auc2$modlist, cvfit_auc2$alpha))

# best performing parameters
best_para_auc2 <- per_matrix_auc2[which.min(per_matrix_auc2[, "Per"]), ]

# fit model using best parameters
fit_fin_auc2 <- glmnetUtils::glmnet(Winning_Bid_Log ~., data = dat_train_aucs,
                               family = gaussian(link = "identity"),
                               alpha = best_para_auc2["Alpha"], 
                               lambda = best_para_auc2["Lambda"])

# predict
pred_vals_auc2 <- predict(fit_fin_auc2, dat_train_aucs)

# check preds
par(mfrow = c(1, 2))
boxplot(exp(dat_train_aucs[["Winning_Bid_Log"]]), ylim = c(0, 40e6))
boxplot(exp(pred_vals_auc2), ylim = c(0, 40e6))

# rmse
sqrt(sum((exp(dat_train_aucs[["Winning_Bid_Log"]]) - exp(pred_vals_auc2))^2) / length(pred_vals_auc2))
```

### Variable Importance

#### EW_Diff

```{r}
# coefficients
coefft_auc <- coef(fit_fin_auc, s = "lambda.min")
coef_ordered_auc <- coefft_auc[order(abs(coefft_auc[, 1]), decreasing = TRUE), ]
signum_auc <- coef_ordered_auc[-1] |> sign()

# print est model parameters
knitr::kable(best_para_auc, col.names = c("Final Model"))

# generate data for varImp plot
TopvarImp_auc <- varImp(fit_fin_auc, lambda = fit_fin_auc$lambda)  %>%
   dplyr::filter(Overall != 0) %>% 
   arrange(desc(Overall)) %>% 
   slice_max(Overall, n = 10)

# Plot
plot_varimp_auc <- ggplot2::ggplot(TopvarImp_auc, aes(x = reorder(rownames(TopvarImp_auc), Overall), y = Overall)) +
  geom_point(color = "blue", size = 4, alpha = 0.6) +
  geom_segment(aes(x = rownames(TopvarImp_auc), xend = rownames(TopvarImp_auc), y = 0, yend = Overall), 
               color = "skyblue") +
  xlab("Variable") +
  ylab("Overall Importance") +
  theme_light() +
  coord_flip() 

# plot
plot_varimp_auc

# signs
knitr::kable(ifelse(signum_auc < 0, "-", "+"), col.names = "Sign")
```

#### Winning Bid

```{r}
# coefficients
coefft_auc2 <- coef(fit_fin_auc2, s = "lambda.min")
coef_ordered_auc2 <- coefft_auc2[order(abs(coefft_auc2[, 1]), decreasing = TRUE), ]
signum_auc2 <- coef_ordered_auc2[-1] |> sign()

# print est model parameters
knitr::kable(best_para_auc2, col.names = c("Final Model"))

# generate data for varImp plot
TopvarImp_auc2 <- varImp(fit_fin_auc2, lambda = fit_fin_auc2$lambda)  %>%
   dplyr::filter(Overall != 0) %>% 
   arrange(desc(Overall)) %>% 
   slice_max(Overall, n = 10)

# Plot
plot_varimp_auc2 <- ggplot2::ggplot(TopvarImp_auc2, aes(x = reorder(rownames(TopvarImp_auc2), Overall), y = Overall)) +
  geom_point(color = "blue", size = 4, alpha = 0.6) +
  geom_segment(aes(x = rownames(TopvarImp_auc2), xend = rownames(TopvarImp_auc2), y = 0, yend = Overall), 
               color = "skyblue") +
  xlab("Variable") +
  ylab("Overall Importance") +
  theme_light() +
  coord_flip() 

# plot
plot_varimp_auc2

# signs
knitr::kable(ifelse(signum_auc2 < 0, "-", "+"), col.names = "Sign")
```

## Feature Engineering

```{r}
# exclude variables that are not supposed to be in the model
lapply(dat_aucs_eng, \(x){

  # remove
  x$Contract_ID <- NULL
  x$MLOT <- NULL
  x$Eng_Est <- x$Eng_Est / 1e3
  x$EW_Diff <- NULL
  x$Winning_Bid <- x$Winning_Bid / 1e3
  # x$Winning_Bid_Log <- log(x$Winning_Bid)
  # x$Winning_Bid <- NULL
  
  # return
  return(x)
  
}) -> dat_aucs_mod_eng

# assign training set
dat_train_aucs_eng <- dat_aucs_mod_eng[["Train"]]
```

### Cross Validation

#### Winning Bid

```{r}
# cross validation

## RAN ONCE ## 
# cvfit_auc_eng <- glmnetUtils::cva.glmnet(Winning_Bid ~., data = dat_train_aucs_eng,
#                                  family = gaussian(link = "identity"),
#                                  type.measure = "mse", nfolds = 10,
#                                  alpha = c(0.01, seq(0, 1, 0.05),0.99),
#                                  nlambda = 100)
beepr::beep(sound = 1)

# save
# saveRDS(cvfit_auc_eng, "./../../Data/Models/Glmnets/Raw/cvfiteng_norm.RDS")

# read file 
cvfit_auc_eng <- readRDS("./../../Data/Models/Glmnets/Raw/cvfiteng_norm.RDS")

# plot fit
plot(cvfit_auc_eng, c.legend = 0.5, main = "Cross Validation Results")
```

```{r}
# obtain best model
per_matrix_auc3 <- do.call(rbind, Map(function(x, y){

 cbind("Per" = x$cvm,
       "Lambda" = x$lambda,
       "Alpha" = rep(y, length(x$lambda)))

}, cvfit_auc_eng$modlist, cvfit_auc_eng$alpha))

# best performing parameters
best_para_auc3 <- per_matrix_auc3[which.min(per_matrix_auc3[, "Per"]), ]

# fit model using best parameters
fit_fin_auc3 <- glmnetUtils::glmnet(Winning_Bid~., data = dat_train_aucs_eng,
                               family = gaussian(link = "identity"),
                               alpha = best_para_auc3["Alpha"], 
                               lambda = best_para_auc3["Lambda"])

# predict
pred_vals_auc3 <- predict(fit_fin_auc3, dat_train_aucs_eng)

# check preds
par(mfrow = c(1, 2))
boxplot(dat_train_aucs_eng[["Winning_Bid"]], ylim = c(0, 40e3))
boxplot(pred_vals_auc3, ylim = c(0, 40e3))

# rmse
Metrics::rmse(dat_train_aucs_eng[["Winning_Bid"]], pred_vals_auc3)
Metrics::mae(dat_train_aucs_eng[["Winning_Bid"]], pred_vals_auc3)
```

```{r}
# fit model using best parameters
fit_fin_test <- glmnetUtils::glmnet(Winning_Bid ~ ., data = dat_aucs_mod_eng[[2]],
                               family = gaussian(link = "identity"),
                               alpha = best_para_auc3["Alpha"], 
                               lambda = best_para_auc3["Lambda"])

# predict
pred_vals_test <- predict(fit_fin_test, dat_aucs_mod_eng[[2]], ylim = c(0, 20e3))

# long dataset for boxplot
rbind(cbind(dat_aucs_mod_eng[[2]][["Winning_Bid"]], "Act."),
      cbind(pred_vals_test, "Lasso Reg."),
      cbind(dat_aucs_mod_eng[[2]][["Eng_Est"]], "Eng. Est."))|> as.data.frame()|> 
      setNames(c("Award_Price", "Model")) -> dat_box


# change 
within(dat_box,{
        Award_Price <- as.numeric(Award_Price)
        Model <- factor(Model, levels = c("Act.", "Lasso Reg.", "Eng. Est."))
        }) -> dat_box

# save data
# saveRDS(dat_box, "./../../Data/Misc Data/Figure_Data/Lasso_Performance.RDS")

# save
# pdf("./../../Data/Misc Data/Figures/Actual_Lasso_Eng_Est.pdf")

# datbox
boxplot(as.numeric(dat_box[, 1]) ~ dat_box[, 2], xlab = "", ylab = "Award Price",
        ylim = c(0, 20e3), pch = 19, outcol = "darkorchid", 
        col = c("cornflowerblue", "forestgreen", "firebrick"), main = "Quality of Prediction")

# plot device
# dev.off()

# rmse
sapply(list(pred_vals_test, dat_aucs_mod_eng[[2]][["Eng_Est"]]), \(x){
  
  sapply(list(Metrics::rmse, Metrics::mae), \(fun){
    
      fun(dat_aucs_mod_eng[[2]][["Winning_Bid"]], x)
    
  }) |> setNames(c("RMSE", "MAE"))

}) |> knitr::kable(col.names = c("Lasso Model", "Eng. Estimate"))
```

```{r}
# coefficients
coefft_auc3 <- coef(fit_fin_auc3, s = "lambda.min")
coef_ordered_auc3 <- coefft_auc3[order(abs(coefft_auc3[, 1]), decreasing = TRUE), ]
signum_auc3 <- coef_ordered_auc3[-1] |> sign()

# print est model parameters
knitr::kable(best_para_auc3, col.names = c("Final Model"))

# generate data for varImp plot
TopvarImp_auc3 <- varImp(fit_fin_auc3, lambda = fit_fin_auc3$lambda)  %>%
   dplyr::filter(Overall != 0) %>% 
   arrange(desc(Overall)) %>% 
   slice_max(Overall, n = 10)

# Plot
plot_varimp_auc3 <- ggplot2::ggplot(TopvarImp_auc3, aes(x = reorder(rownames(TopvarImp_auc3), Overall), y = Overall)) +
  geom_point(color = "blue", size = 4, alpha = 0.6) +
  geom_segment(aes(x = rownames(TopvarImp_auc3), xend = rownames(TopvarImp_auc3), y = 0, yend = Overall), 
               color = "skyblue") +
  xlab("Variable") +
  ylab("Overall Importance") +
  theme_light() +
  coord_flip() 

# plot
plot_varimp_auc3

# signs
knitr::kable(ifelse(signum_auc3 < 0, "-", "+"), col.names = "Sign")
```

